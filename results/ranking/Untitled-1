Phase 3: Evaluation

This phase involves evaluating the results generated by the IR system. Results for the following runs have been generated.
    1) tf.idf
    2) tf.idf with stopping
    3) Smoothed Query Likelihood
    4) Smoothed Query Likelihood with stopping
    5) Smoothed Query Likelihood with Pseudo Relevance Feedback
    6) BM25
    7) BM25 with stopping
    8) Lucene

evaluator.py: Defines a class Evaluator which is used to generate reports for a single run. file_name and run_name are passed as arguments to the constructor. evaluate() will calculate the following metrics for all queries.
    1) Precision table
    2) Recall table
    3) Precision@5 table
    4) Precision@20 table
    5) Mean Average Precision
    6) Mean Reciprocal Rank



Document parsing    Shyam
Indexing    Shaurya
Retrieval Model - BM25  Chetan
Retrieval Model - tf.idf    Shaurya
Retrieval Model - Smoothed Query Likelihood Shyam
Retrieval Model Lucene - Shyam
Stopping    Chetan
Stemming    Chetan
Pseudo Relevance Feedback   Shaurya
Snippet Generation  Shyam
Evaluation  Shaurya
Documentation   Chetan


